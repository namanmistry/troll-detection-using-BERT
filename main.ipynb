{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"troll.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Get fucking real dude.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>She is as dirty as they come  and that crook ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>why did you fuck it up. I could do it all day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dude they dont finish enclosing the fucking s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>WTF are you talking about Men? No men thats n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  class                                              tweet\n",
       "0           0      1                             Get fucking real dude.\n",
       "1           1      1   She is as dirty as they come  and that crook ...\n",
       "2           2      1   why did you fuck it up. I could do it all day...\n",
       "3           3      1   Dude they dont finish enclosing the fucking s...\n",
       "4           4      1   WTF are you talking about Men? No men thats n..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20001 entries, 0 to 20000\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   class   20001 non-null  int64 \n",
      " 1   tweet   20001 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from tqdm import tqdm\n",
    "\n",
    "def clean_text(raw_text):\n",
    "    # Remove unnecessary symbols and numbers\n",
    "    cleaned_text = re.sub('[^a-zA-Z]', ' ', raw_text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = cleaned_text.split()\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Perform stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    # Perform lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    # Join the cleaned words back into a single string\n",
    "    cleaned_text = ' '.join(words)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "data['cleaned_text'] = data['tweet'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       get fuck real dude\n",
       "1        dirti come crook rengel dem fuck corrupt joke ...\n",
       "2        fuck could day let hour ping later sched write...\n",
       "3        dude dont finish enclos fuck shower hate half ...\n",
       "4                          wtf talk men men that menag gay\n",
       "                               ...                        \n",
       "19996                                     dont complain go\n",
       "19997    bahah yeah total gonna get piss talk mhm that ...\n",
       "19998             hahahahaha im evil mwahahahahahahahahaha\n",
       "19999                                    someth uniqu ohio\n",
       "20000                                  biggest gossip know\n",
       "Name: cleaned_text, Length: 20001, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "balance_count = data['class'].value_counts()\n",
    "\n",
    "plt.bar(x=balance_count.index, height=balance_count.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0460f1eea1b45149b61f06a34be47bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\LLM\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\naman\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d220e3274979414f95cef1fd6eecf2a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ae15444b9d43c595a8d19e2308be7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a544b07d394531b5c8e35be1881af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/536M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your training data\n",
    "train_texts = list(data['tweet'].values)\n",
    "train_labels = list(data['class'].values)  # Corresponding labels (1 or 0) for the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the input texts\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorFlow datasets for training\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    ")).shuffle(len(train_texts)).batch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer, loss function, and metrics\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " failed to allocate memory\n\t [[node Adam/Adam/update/mul_4 (defined at d:\\LLM\\venv\\lib\\site-packages\\transformers\\modeling_tf_utils.py:1604) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_45801]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizer, loss\u001b[39m=\u001b[39mloss, metrics\u001b[39m=\u001b[39m[metric])\n\u001b[0;32m      4\u001b[0m \u001b[39m# Fine-tune the model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_dataset, epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "File \u001b[1;32md:\\LLM\\venv\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1185\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\LLM\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\LLM\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:950\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    947\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    949\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 950\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    951\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m   _, _, _, filtered_flat_args \u001b[39m=\u001b[39m \\\n\u001b[0;32m    953\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    954\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32md:\\LLM\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3040\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32md:\\LLM\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1964\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\LLM\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32md:\\LLM\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  failed to allocate memory\n\t [[node Adam/Adam/update/mul_4 (defined at d:\\LLM\\venv\\lib\\site-packages\\transformers\\modeling_tf_utils.py:1604) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_45801]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "c\n",
    "\n",
    "# Fine-tune the model\n",
    "model.fit(train_dataset, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[ 3919,   545,   655, ..., 50256, 50256, 50256],\n",
       "       [10814,   220,   645, ..., 50256, 50256, 50256],\n",
       "       [13775, 32744, 13896, ..., 50256, 50256, 50256],\n",
       "       ...,\n",
       "       [29214, 25320,   284, ..., 50256, 50256, 50256],\n",
       "       [43669,  4818, 21551, ..., 50256, 50256, 50256],\n",
       "       [ 1312,   766,   345, ..., 50256, 50256, 50256]]), 'attention_mask': array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
